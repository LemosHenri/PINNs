{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp \n",
    "from jax import random\n",
    "import equinox as eqx \n",
    "import optax\n",
    "import matplotlib.pyplot as plt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equação do Calor\n",
    "\n",
    "A equação do calor é dada através da seguinte equação diferencial:\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial u}{\\partial t} = \\alpha \\dfrac{\\partial^2 u}{\\partial x^2}, \\hspace{1cm}  x\\in [0,1],t\\in [0,1]\n",
    "$$\n",
    "\n",
    "onde $\\alpha = 0.4$, $u(0,t) = u(1,t) = 0$ e $u(x,0) = \\sin(\\dfrac{n \\pi x}{L}), 0 < x < L$ e $n = 1,2,3,\\ldots$.\n",
    "\n",
    "Teremos que $L = 1$, como a largura da barra e $n=1$ a frequencia senoidal da condição inicial.\n",
    "\n",
    "A solução exata é dada por $u(x,t) = e^{\\frac{-n^2 \\pi^2 \\alpha t}{L^2}} \\sin(\\dfrac{n \\pi x}{L})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "#PARAMETROS\n",
    "alpha = 0.4\n",
    "L = 1\n",
    "N = 1\n",
    "\n",
    "#DECLARAÇÃO DO DOMÍNIO\n",
    "x_dom = (0, 1)\n",
    "t_dom = (0, 1)\n",
    "batch_size = 1000\n",
    "\n",
    "#OBTENÇÃO DOS DADOS DE TREINAMENTO\n",
    "N_SAMPLES = 200\n",
    "key_x, key_t, key_model = jax.random.split(jax.random.PRNGKey(0),3)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "#PONTOS INTERNOS\n",
    "x_samples = random.uniform(key_x, (N_SAMPLES, 1), minval=x_dom[0], maxval=x_dom[1])\n",
    "t_samples = random.uniform(key_t, (N_SAMPLES, 1), minval=t_dom[0], maxval=t_dom[1])\n",
    "intern_points = jnp.concatenate([x_samples, t_samples], 1)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "#Condição de contorno 1: u[0, t]\n",
    "x_b1 = jnp.zeros_like(x_samples)\n",
    "bc_1 = jnp.concatenate([x_b1, t_samples], 1)\n",
    "bc1_target = jnp.zeros_like(x_samples)\n",
    "\n",
    "#Condição de contorno 1: u[1, t]\n",
    "x_b2 = jnp.ones_like(x_samples)\n",
    "bc_2 = jnp.concatenate([x_b2, t_samples], 1)\n",
    "bc2_target = jnp.zeros_like(x_samples)\n",
    "\n",
    "#Condição inicial: u[x, 0]\n",
    "t_ic = jnp.zeros_like(t_samples) \n",
    "ic = jnp.concatenate([x_samples, t_ic], 1)\n",
    "ic_target = jnp.ones_like(t_samples) * jnp.sin((N * jnp.pi * x_samples) / L)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "geometry = [bc_1, bc_2, ic]\n",
    "target = [bc1_target, bc2_target, ic_target]\n",
    "\n",
    "#plt.scatter(x_b1, t_samples)\n",
    "#plt.scatter(x_b2, t_samples)\n",
    "#plt.scatter(x_samples, t_ic)\n",
    "#plt.scatter(x_samples, t_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Linear:\n",
    "    weight: jnp.ndarray\n",
    "    bias: jnp.ndarray\n",
    "\n",
    "    def __init__(self, n_input: int, n_output: int, key = jax.random.PRNGKey(0)):\n",
    "\n",
    "        self.weight = random.uniform(key, (n_input, n_output))\n",
    "        self.bias = random.uniform(key, (n_output, ))\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return jnp.dot(input, self.weight) + self.bias\n",
    "    \n",
    "class NeuralNetwork:\n",
    "\n",
    "    layers: list[Linear]\n",
    "    activation: callable\n",
    "\n",
    "    def __init__(self, layers: list[int], activation_func):\n",
    "\n",
    "        self.layers = [Linear(m, n) for m, n in zip(layers[:-1], layers[1:])]\n",
    "        self.activation = activation_func\n",
    "\n",
    "    def __call__(self, input):\n",
    "        \n",
    "        *hidden, last = self.layers\n",
    "\n",
    "        for layer in hidden:\n",
    "            out = layer(input)\n",
    "            return last(self.activation(out))\n",
    "\n",
    "class PINNs: \n",
    "\n",
    "    model: NeuralNetwork \n",
    "    residual_function: callable\n",
    "\n",
    "    def __init__(self, layers: list[int], act_function, residual):\n",
    "        self.model = NeuralNetwork(layers, act_function)\n",
    "        self.residual_function = residual\n",
    "        \n",
    "    def MSE_loss(self, input, target):\n",
    "        out_prediction = self.model(input)\n",
    "        return jnp.mean((target - out_prediction)**2)\n",
    "\n",
    "    def loss_residual(self, input):\n",
    "        out = self.residual_function(self.model, input)\n",
    "        print(out)\n",
    "\n",
    "    def loss_conditions(self, geometry, target):\n",
    "        \n",
    "        loss_list = []\n",
    "        for g, t in zip(geometry, target):\n",
    "            l = self.MSE_loss(g, t)\n",
    "            loss_list.append(l)\n",
    "        return sum(loss_list)\n",
    "\n",
    "    def trainning(self, lr, epochs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Gradient only defined for scalar-output functions. Output had shape: (200, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m     26\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m model, x, t: model(jnp\u001b[38;5;241m.\u001b[39mconcatenate((x,t),\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 27\u001b[0m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api.py:715\u001b[0m, in \u001b[0;36m_check_scalar\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(aval, ShapedArray):\n\u001b[1;32m    714\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m aval\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m ():\n\u001b[0;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maval\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad abstract value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Gradient only defined for scalar-output functions. Output had shape: (200, 1)."
     ]
    }
   ],
   "source": [
    "from jax import jacobian, grad, hessian, jacfwd, jacrev\n",
    "\n",
    "#DECLARAÇÃO DA EQUAÇÃO RESIDUAL \n",
    "def eq_residual(model, x, t):\n",
    "\n",
    "    input = jnp.concatenate(x, t)\n",
    "    u = model(input)\n",
    "\n",
    "    u_t = grad(u, argnums=1)(input)\n",
    "    u_xx = grad(grad(u, argnums=0), argnums=0)(input)\n",
    "\n",
    "    return u_t - alpha * u_xx\n",
    "\n",
    "LAYERS = [2, 20, 20, 20, 1]\n",
    "model = PINNs(layers = LAYERS, act_function = jax.nn.tanh, residual = eq_residual)\n",
    "#model.loss_conditions(geometry, target)\n",
    "\n",
    "u = NeuralNetwork(LAYERS, jax.nn.tanh)\n",
    "input = jnp.concatenate([x_samples, t_samples],1)\n",
    "\n",
    "def res(model, x, t):\n",
    "    input = jnp.concatenate((x, t),1)\n",
    "    return model(input)\n",
    "    \n",
    "\n",
    "f = lambda model, x, t: model(jnp.concatenate((x,t),1))\n",
    "grad(f, argnums=1)(u, x_samples, t_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
